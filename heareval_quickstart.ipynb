{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heareval demo",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYQLwJp4caUE",
        "outputId": "ab7c383d-cc4c-49f9-fae9-4b64118ba4f7"
      },
      "source": [
        "# Install heareval, and a baseline model to evaluate\n",
        "!pip3 install -q git+https://github.com/neuralaudio/hear-eval-kit.git@v2021.0.3\n",
        "!pip3 install -q git+https://github.com/neuralaudio/hear-baseline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 52.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 922 kB 57.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 63.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 45.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 61.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 67.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 119 kB 44.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 282 kB 57.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 45.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 67.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 46.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 42.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 41.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 57.2 MB/s \n",
            "\u001b[?25h  Building wheel for heareval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dcase-util (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sed-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cfn-flip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 393 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 33.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72.3 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 59.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 56.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 38.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 109 kB 55.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 546 kB 43.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.1 MB/s \n",
            "\u001b[?25h  Building wheel for hearbaseline (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T4NRNaxckCN",
        "outputId": "251bdca2-0eb4-4db0-ac86-6da1065c7e80"
      },
      "source": [
        "# Get a tiny subsampled version of the speech commands open task from github\n",
        "# Since this model is samplerate 44100, we get that data set\n",
        "!wget --no-check-certificate -c https://raw.githubusercontent.com/neuralaudio/hear2021-open-tasks-downsampled/main/preprocessed/hear-20210906-2021.0.2-speech_commands-v0.0.2-small-44100.tar.gz && tar zxf hear-20210906-2021.0.2-speech_commands-v0.0.2-small-44100.tar.gz"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-13 15:51:53--  https://raw.githubusercontent.com/neuralaudio/hear2021-open-tasks-downsampled/main/preprocessed/hear-20210906-2021.0.2-speech_commands-v0.0.2-small-44100.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1vJQPazeJM3",
        "outputId": "9a1f5452-d4fa-4fb8-8754-f3aa7167e723"
      },
      "source": [
        "# Compute embeddings for each speech command\n",
        "# This will create embeddings in embeddings/{module}/{task}\n",
        "!python -m heareval.embeddings.runner hearbaseline --tasks-dir hear-20210906-2021.0.2/tasks/ --embeddings-dir embeddings"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings\n",
            "Importing hearbaseline\n",
            "  0% 0/1 [00:00<?, ?it/s]Getting embeddings for split: train\n",
            "Estimated batch size = 39\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "100% 2/2 [00:00<00:00, 15.22it/s]\n",
            "\n",
            "100% 56/56 [00:00<00:00, 3070.06it/s]\n",
            "\n",
            "100% 56/56 [00:00<00:00, 2165.36it/s]\n",
            "Getting embeddings for split: valid\n",
            "Estimated batch size = 39\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "100% 4/4 [00:00<00:00, 17.91it/s]\n",
            "\n",
            "100% 132/132 [00:00<00:00, 2982.49it/s]\n",
            "\n",
            "100% 132/132 [00:00<00:00, 2084.39it/s]\n",
            "Getting embeddings for split: test\n",
            "Estimated batch size = 39\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "100% 3/3 [00:00<00:00, 18.74it/s]\n",
            "\n",
            "100% 96/96 [00:00<00:00, 3100.43it/s]\n",
            "\n",
            "100% 96/96 [00:00<00:00, 2218.12it/s]\n",
            "...computed embeddings in 0.7960822582244873 sec (GPU max mem None) for speech_commands-v0.0.2-small using hearbaseline {}\n",
            "100% 1/1 [00:00<00:00,  1.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTvueObCgzQj",
        "outputId": "6da8126e-0116-446f-86a2-b71afa7824a0"
      },
      "source": [
        "# Run downstream prediction on the open task/\n",
        "# Given embeddings in embeddings in embeddings/{module}/{task}\n",
        "# train a downstream predictor with one grid point.\n",
        "!python -m heareval.predictions.runner embeddings/hearbaseline/* --grid-points 1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/1 [00:00<?, ?it/s]Computing predictions for speech_commands-v0.0.2-small\n",
            "Global seed set to 42\n",
            "\n",
            "\rgrid:   0% 0/1 [00:00<?, ?it/s]\u001b[Atrying grid point {'batch_size': 1024, 'check_val_every_n_epoch': 3, 'dropout': 0.1, 'embedding_norm': <class 'torch.nn.modules.linear.Identity'>, 'hidden_dim': 1024, 'hidden_layers': 1, 'hidden_norm': <class 'torch.nn.modules.batchnorm.BatchNorm1d'>, 'initialization': <function xavier_normal_ at 0x7fe10adf88c0>, 'lr': 0.0001, 'max_epochs': 500, 'norm_after_activation': False, 'optim': <class 'torch.optim.adam.Adam'>, 'patience': 20}\n",
            "/usr/local/lib/python3.7/dist-packages/heareval/predictions/task_predictions.py:193: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = self.activation(x)\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "FullyConnectedPrediction                 --                        --\n",
            "├─Sequential: 1-1                        [64, 1024]                --\n",
            "│    └─Linear: 2-1                       [64, 1024]                4,195,328\n",
            "│    └─BatchNorm1d: 2-2                  [64, 1024]                2,048\n",
            "│    └─Dropout: 2-3                      [64, 1024]                --\n",
            "│    └─ReLU: 2-4                         [64, 1024]                --\n",
            "├─Linear: 1-2                            [64, 12]                  12,300\n",
            "├─Softmax: 1-3                           [64, 12]                  --\n",
            "==========================================================================================\n",
            "Total params: 4,209,676\n",
            "Trainable params: 4,209,676\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 269.42\n",
            "==========================================================================================\n",
            "Input size (MB): 1.05\n",
            "Forward/backward pass size (MB): 1.05\n",
            "Params size (MB): 16.84\n",
            "Estimated Total Size (MB): 18.94\n",
            "==========================================================================================\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "\n",
            "\n",
            "\r  0% 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\r100% 56/56 [00:00<00:00, 47944.69it/s]\n",
            "\n",
            "\n",
            "\r  0% 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\r100% 56/56 [00:00<00:00, 8266.09it/s]\n",
            "Getting embeddings for split train, which has 56 instances.\n",
            "\n",
            "\n",
            "\r  0% 0/132 [00:00<?, ?it/s]\u001b[A\u001b[A\r100% 132/132 [00:00<00:00, 62800.38it/s]\n",
            "\n",
            "\n",
            "\r  0% 0/132 [00:00<?, ?it/s]\u001b[A\u001b[A\r100% 132/132 [00:00<00:00, 29450.94it/s]\n",
            "Getting embeddings for split valid, which has 132 instances.\n",
            "\n",
            "  | Name      | Type                     | Params\n",
            "-------------------------------------------------------\n",
            "0 | layernorm | Identity                 | 0     \n",
            "1 | predictor | FullyConnectedPrediction | 4.2 M \n",
            "-------------------------------------------------------\n",
            "4.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.2 M     Total params\n",
            "16.839    Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:323: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n",
            "Epoch 2: 100% 2/2 [00:00<00:00, 19.66it/s, loss=2.74, v_num=0]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 2/2 [00:00<00:00, 10.60it/s, loss=2.59, v_num=0, val_loss=10.70, val_top1_acc=0.00758]\n",
            "Epoch 5: 100% 2/2 [00:00<00:00, 20.27it/s, loss=2.37, v_num=0, val_loss=10.70, val_top1_acc=0.00758]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 2/2 [00:00<00:00, 10.48it/s, loss=2.31, v_num=0, val_loss=3.470, val_top1_acc=0.0152] \n",
            "Epoch 8: 100% 2/2 [00:00<00:00, 20.16it/s, loss=2.23, v_num=0, val_loss=3.470, val_top1_acc=0.0152]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 2/2 [00:00<00:00, 10.91it/s, loss=2.2, v_num=0, val_loss=5.470, val_top1_acc=0.0455] \n",
            "Epoch 11: 100% 2/2 [00:00<00:00, 19.70it/s, loss=2.13, v_num=0, val_loss=5.470, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 2/2 [00:00<00:00, 10.64it/s, loss=2.1, v_num=0, val_loss=6.190, val_top1_acc=0.0455] \n",
            "Epoch 14: 100% 2/2 [00:00<00:00, 18.98it/s, loss=2.05, v_num=0, val_loss=6.190, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 14: 100% 2/2 [00:00<00:00, 10.82it/s, loss=2.02, v_num=0, val_loss=6.950, val_top1_acc=0.0455]\n",
            "Epoch 17: 100% 2/2 [00:00<00:00, 19.82it/s, loss=1.98, v_num=0, val_loss=6.950, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 17: 100% 2/2 [00:00<00:00, 10.55it/s, loss=1.96, v_num=0, val_loss=9.620, val_top1_acc=0.0455]\n",
            "Epoch 20: 100% 2/2 [00:00<00:00, 20.23it/s, loss=1.93, v_num=0, val_loss=9.620, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 20: 100% 2/2 [00:00<00:00, 11.20it/s, loss=1.86, v_num=0, val_loss=9.760, val_top1_acc=0.0455]\n",
            "Epoch 23: 100% 2/2 [00:00<00:00, 19.79it/s, loss=1.78, v_num=0, val_loss=9.760, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 23: 100% 2/2 [00:00<00:00, 10.98it/s, loss=1.77, v_num=0, val_loss=7.950, val_top1_acc=0.0455]\n",
            "Epoch 26: 100% 2/2 [00:00<00:00, 20.29it/s, loss=1.72, v_num=0, val_loss=7.950, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 26: 100% 2/2 [00:00<00:00, 11.24it/s, loss=1.71, v_num=0, val_loss=8.110, val_top1_acc=0.0455]\n",
            "Epoch 29: 100% 2/2 [00:00<00:00, 19.54it/s, loss=1.67, v_num=0, val_loss=8.110, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 29: 100% 2/2 [00:00<00:00, 11.01it/s, loss=1.65, v_num=0, val_loss=8.270, val_top1_acc=0.0455]\n",
            "Epoch 32: 100% 2/2 [00:00<00:00, 20.16it/s, loss=1.63, v_num=0, val_loss=8.270, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 32: 100% 2/2 [00:00<00:00, 10.76it/s, loss=1.63, v_num=0, val_loss=8.970, val_top1_acc=0.0303]\n",
            "Epoch 35: 100% 2/2 [00:00<00:00, 18.81it/s, loss=1.61, v_num=0, val_loss=8.970, val_top1_acc=0.0303]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 35: 100% 2/2 [00:00<00:00, 10.69it/s, loss=1.6, v_num=0, val_loss=11.60, val_top1_acc=0.000]  \n",
            "Epoch 38: 100% 2/2 [00:00<00:00, 19.15it/s, loss=1.59, v_num=0, val_loss=11.60, val_top1_acc=0.000]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 38: 100% 2/2 [00:00<00:00, 10.73it/s, loss=1.59, v_num=0, val_loss=12.40, val_top1_acc=0.000]\n",
            "Epoch 41: 100% 2/2 [00:00<00:00, 20.22it/s, loss=1.58, v_num=0, val_loss=12.40, val_top1_acc=0.000]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 41: 100% 2/2 [00:00<00:00, 11.19it/s, loss=1.57, v_num=0, val_loss=12.90, val_top1_acc=0.000]\n",
            "Epoch 44: 100% 2/2 [00:00<00:00, 19.85it/s, loss=1.56, v_num=0, val_loss=12.90, val_top1_acc=0.000]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 44: 100% 2/2 [00:00<00:00, 11.03it/s, loss=1.56, v_num=0, val_loss=15.00, val_top1_acc=0.000]\n",
            "Epoch 47: 100% 2/2 [00:00<00:00, 20.92it/s, loss=1.55, v_num=0, val_loss=15.00, val_top1_acc=0.000]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 47: 100% 2/2 [00:00<00:00, 11.28it/s, loss=1.55, v_num=0, val_loss=13.80, val_top1_acc=0.00758]\n",
            "Epoch 50: 100% 2/2 [00:00<00:00, 19.86it/s, loss=1.54, v_num=0, val_loss=13.80, val_top1_acc=0.00758]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 50: 100% 2/2 [00:00<00:00, 11.20it/s, loss=1.54, v_num=0, val_loss=12.60, val_top1_acc=0.00758]\n",
            "Epoch 53: 100% 2/2 [00:00<00:00, 20.22it/s, loss=1.52, v_num=0, val_loss=12.60, val_top1_acc=0.00758]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 53: 100% 2/2 [00:00<00:00, 11.15it/s, loss=1.52, v_num=0, val_loss=14.50, val_top1_acc=0.00758]\n",
            "Epoch 56: 100% 2/2 [00:00<00:00, 18.45it/s, loss=1.52, v_num=0, val_loss=14.50, val_top1_acc=0.00758]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 56: 100% 2/2 [00:00<00:00, 10.40it/s, loss=1.51, v_num=0, val_loss=16.10, val_top1_acc=0.0455] \n",
            "Epoch 59: 100% 2/2 [00:00<00:00, 19.76it/s, loss=1.51, v_num=0, val_loss=16.10, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 59: 100% 2/2 [00:00<00:00, 11.24it/s, loss=1.51, v_num=0, val_loss=14.40, val_top1_acc=0.0455]\n",
            "Epoch 62: 100% 2/2 [00:00<00:00, 18.70it/s, loss=1.5, v_num=0, val_loss=14.40, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 62: 100% 2/2 [00:00<00:00, 10.87it/s, loss=1.49, v_num=0, val_loss=13.60, val_top1_acc=0.0379]\n",
            "Epoch 65: 100% 2/2 [00:00<00:00, 19.77it/s, loss=1.49, v_num=0, val_loss=13.60, val_top1_acc=0.0379]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 65: 100% 2/2 [00:00<00:00, 11.04it/s, loss=1.49, v_num=0, val_loss=13.90, val_top1_acc=0.0455]\n",
            "Epoch 68: 100% 2/2 [00:00<00:00, 20.40it/s, loss=1.49, v_num=0, val_loss=13.90, val_top1_acc=0.0455]  \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 68: 100% 2/2 [00:00<00:00, 11.30it/s, loss=1.49, v_num=0, val_loss=13.70, val_top1_acc=0.0379]\n",
            "Epoch 68: 100% 2/2 [00:00<00:00, 11.10it/s, loss=1.49, v_num=0, val_loss=13.70, val_top1_acc=0.0379]\n",
            "FIT Profiler Report\n",
            "\n",
            "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
            "--------------------------------------------------------------------------------------------------------------------------------------\n",
            "Total                              \t|  -              \t|_              \t|  14.155         \t|  100 %          \t|\n",
            "--------------------------------------------------------------------------------------------------------------------------------------\n",
            "run_training_epoch                 \t|  0.20427        \t|69             \t|  14.094         \t|  99.575         \t|\n",
            "run_training_batch                 \t|  0.087897       \t|69             \t|  6.0649         \t|  42.847         \t|\n",
            "optimizer_step_and_closure_0       \t|  0.084469       \t|69             \t|  5.8284         \t|  41.176         \t|\n",
            "get_train_batch                    \t|  0.059237       \t|69             \t|  4.0873         \t|  28.876         \t|\n",
            "training_step_and_backward         \t|  0.042118       \t|69             \t|  2.9062         \t|  20.532         \t|\n",
            "backward                           \t|  0.020475       \t|69             \t|  1.4128         \t|  9.9811         \t|\n",
            "evaluation_step_and_end            \t|  0.047615       \t|23             \t|  1.0952         \t|  7.737          \t|\n",
            "validation_step                    \t|  0.047331       \t|23             \t|  1.0886         \t|  7.6908         \t|\n",
            "model_forward                      \t|  0.015775       \t|69             \t|  1.0885         \t|  7.69           \t|\n",
            "training_step                      \t|  0.015545       \t|69             \t|  1.0726         \t|  7.5777         \t|\n",
            "on_validation_end                  \t|  0.036942       \t|23             \t|  0.84968        \t|  6.0028         \t|\n",
            "on_train_batch_end                 \t|  0.00057469     \t|69             \t|  0.039654       \t|  0.28015        \t|\n",
            "training_batch_to_device           \t|  0.00039166     \t|69             \t|  0.027025       \t|  0.19092        \t|\n",
            "on_train_epoch_start               \t|  0.00037288     \t|69             \t|  0.025728       \t|  0.18177        \t|\n",
            "evaluation_batch_to_device         \t|  0.00091521     \t|23             \t|  0.02105        \t|  0.14871        \t|\n",
            "on_validation_start                \t|  0.00080088     \t|23             \t|  0.01842        \t|  0.13014        \t|\n",
            "on_train_epoch_end                 \t|  0.00022232     \t|69             \t|  0.01534        \t|  0.10837        \t|\n",
            "on_validation_batch_end            \t|  0.000279       \t|23             \t|  0.006417       \t|  0.045335       \t|\n",
            "on_batch_start                     \t|  7.8453e-05     \t|69             \t|  0.0054133      \t|  0.038244       \t|\n",
            "on_after_backward                  \t|  7.1489e-05     \t|69             \t|  0.0049328      \t|  0.034849       \t|\n",
            "on_validation_batch_start          \t|  0.0001891      \t|23             \t|  0.0043493      \t|  0.030727       \t|\n",
            "on_before_backward                 \t|  5.6609e-05     \t|69             \t|  0.0039061      \t|  0.027595       \t|\n",
            "on_before_optimizer_step           \t|  4.9784e-05     \t|69             \t|  0.0034351      \t|  0.024268       \t|\n",
            "on_epoch_start                     \t|  3.7118e-05     \t|92             \t|  0.0034149      \t|  0.024125       \t|\n",
            "on_train_batch_start               \t|  4.7122e-05     \t|69             \t|  0.0032514      \t|  0.022971       \t|\n",
            "on_epoch_end                       \t|  3.2417e-05     \t|92             \t|  0.0029824      \t|  0.02107        \t|\n",
            "on_before_zero_grad                \t|  3.9666e-05     \t|69             \t|  0.002737       \t|  0.019336       \t|\n",
            "on_batch_end                       \t|  3.783e-05      \t|69             \t|  0.0026103      \t|  0.018441       \t|\n",
            "training_step_end                  \t|  3.2972e-05     \t|69             \t|  0.0022751      \t|  0.016073       \t|\n",
            "validation_step_end                \t|  7.6789e-05     \t|23             \t|  0.0017661      \t|  0.012477       \t|\n",
            "on_validation_epoch_end            \t|  5.1017e-05     \t|23             \t|  0.0011734      \t|  0.0082898      \t|\n",
            "on_validation_epoch_start          \t|  2.9762e-05     \t|23             \t|  0.00068453     \t|  0.0048361      \t|\n",
            "on_train_start                     \t|  0.0003531      \t|1              \t|  0.0003531      \t|  0.0024946      \t|\n",
            "on_train_end                       \t|  0.00030467     \t|1              \t|  0.00030467     \t|  0.0021524      \t|\n",
            "on_fit_start                       \t|  4.1322e-05     \t|1              \t|  4.1322e-05     \t|  0.00029193     \t|\n",
            "on_before_accelerator_backend_setup\t|  2.2492e-05     \t|1              \t|  2.2492e-05     \t|  0.0001589      \t|\n",
            "on_train_dataloader                \t|  1.9524e-05     \t|1              \t|  1.9524e-05     \t|  0.00013793     \t|\n",
            "on_val_dataloader                  \t|  1.7666e-05     \t|1              \t|  1.7666e-05     \t|  0.00012481     \t|\n",
            "\n",
            "[0.04545454680919647, 9, {\"batch_size\": 1024, \"check_val_every_n_epoch\": 3, \"dropout\": 0.1, \"embedding_norm\": \"<class 'torch.nn.modules.linear.Identity'>\", \"hidden_dim\": 1024, \"hidden_layers\": 1, \"hidden_norm\": \"<class 'torch.nn.modules.batchnorm.BatchNorm1d'>\", \"initialization\": \"<function xavier_normal_ at 0x7fe10adf88c0>\", \"lr\": 0.0001, \"max_epochs\": 500, \"norm_after_activation\": false, \"optim\": \"<class 'torch.optim.adam.Adam'>\", \"patience\": 20}, [], \"embeddings/hearbaseline/speech_commands-v0.0.2-small\"]\n",
            "\n",
            "grid: 100% 1/1 [00:14<00:00, 14.30s/it]\n",
            "\n",
            "Best validation score 0.04545454680919647 {'batch_size': 1024, 'check_val_every_n_epoch': 3, 'dropout': 0.1, 'embedding_norm': <class 'torch.nn.modules.linear.Identity'>, 'hidden_dim': 1024, 'hidden_layers': 1, 'hidden_norm': <class 'torch.nn.modules.batchnorm.BatchNorm1d'>, 'initialization': <function xavier_normal_ at 0x7fe10adf88c0>, 'lr': 0.0001, 'max_epochs': 500, 'norm_after_activation': False, 'optim': <class 'torch.optim.adam.Adam'>, 'patience': 20} embeddings/hearbaseline/speech_commands-v0.0.2-small\n",
            "logs/embeddings/hearbaseline/speech_commands-v0.0.2-small/default/version_0/checkpoints/epoch=8-step=8.ckpt\n",
            "\n",
            "100% 96/96 [00:00<00:00, 51273.80it/s]\n",
            "\n",
            "100% 96/96 [00:00<00:00, 25840.92it/s]\n",
            "Getting embeddings for split test, which has 96 instances.\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:679: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
            "  \"`trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\"\n",
            "Testing: 0it [00:00, ?it/s]--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_loss': 19.56671142578125,\n",
            " 'test_score': 0.0833333358168602,\n",
            " 'test_top1_acc': 0.0833333358168602}\n",
            "--------------------------------------------------------------------------------\n",
            "Testing: 100% 1/1 [00:00<00:00,  9.55it/s]\n",
            "TEST Profiler Report\n",
            "\n",
            "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n",
            "Total                              \t|  -              \t|_              \t|  14.357         \t|  100 %          \t|\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n",
            "run_training_epoch                 \t|  0.20427        \t|69             \t|  14.094         \t|  98.172         \t|\n",
            "run_training_batch                 \t|  0.087897       \t|69             \t|  6.0649         \t|  42.244         \t|\n",
            "optimizer_step_and_closure_0       \t|  0.084469       \t|69             \t|  5.8284         \t|  40.596         \t|\n",
            "get_train_batch                    \t|  0.059237       \t|69             \t|  4.0873         \t|  28.469         \t|\n",
            "training_step_and_backward         \t|  0.042118       \t|69             \t|  2.9062         \t|  20.242         \t|\n",
            "backward                           \t|  0.020475       \t|69             \t|  1.4128         \t|  9.8405         \t|\n",
            "evaluation_step_and_end            \t|  0.047109       \t|24             \t|  1.1306         \t|  7.8751         \t|\n",
            "validation_step                    \t|  0.047331       \t|23             \t|  1.0886         \t|  7.5824         \t|\n",
            "model_forward                      \t|  0.015775       \t|69             \t|  1.0885         \t|  7.5816         \t|\n",
            "training_step                      \t|  0.015545       \t|69             \t|  1.0726         \t|  7.4709         \t|\n",
            "on_validation_end                  \t|  0.036942       \t|23             \t|  0.84968        \t|  5.9182         \t|\n",
            "on_train_batch_end                 \t|  0.00057469     \t|69             \t|  0.039654       \t|  0.2762         \t|\n",
            "test_step                          \t|  0.035183       \t|1              \t|  0.035183       \t|  0.24506        \t|\n",
            "training_batch_to_device           \t|  0.00039166     \t|69             \t|  0.027025       \t|  0.18823        \t|\n",
            "on_train_epoch_start               \t|  0.00037288     \t|69             \t|  0.025728       \t|  0.17921        \t|\n",
            "evaluation_batch_to_device         \t|  0.00091155     \t|24             \t|  0.021877       \t|  0.15238        \t|\n",
            "on_validation_start                \t|  0.00080088     \t|23             \t|  0.01842        \t|  0.1283         \t|\n",
            "on_train_epoch_end                 \t|  0.00022232     \t|69             \t|  0.01534        \t|  0.10685        \t|\n",
            "on_validation_batch_end            \t|  0.000279       \t|23             \t|  0.006417       \t|  0.044696       \t|\n",
            "on_batch_start                     \t|  7.8453e-05     \t|69             \t|  0.0054133      \t|  0.037705       \t|\n",
            "on_after_backward                  \t|  7.1489e-05     \t|69             \t|  0.0049328      \t|  0.034358       \t|\n",
            "on_validation_batch_start          \t|  0.0001891      \t|23             \t|  0.0043493      \t|  0.030294       \t|\n",
            "on_before_backward                 \t|  5.6609e-05     \t|69             \t|  0.0039061      \t|  0.027207       \t|\n",
            "on_epoch_start                     \t|  3.7032e-05     \t|93             \t|  0.0034439      \t|  0.023988       \t|\n",
            "on_before_optimizer_step           \t|  4.9784e-05     \t|69             \t|  0.0034351      \t|  0.023926       \t|\n",
            "on_train_batch_start               \t|  4.7122e-05     \t|69             \t|  0.0032514      \t|  0.022647       \t|\n",
            "on_epoch_end                       \t|  3.2523e-05     \t|93             \t|  0.0030247      \t|  0.021068       \t|\n",
            "on_before_zero_grad                \t|  3.9666e-05     \t|69             \t|  0.002737       \t|  0.019064       \t|\n",
            "on_batch_end                       \t|  3.783e-05      \t|69             \t|  0.0026103      \t|  0.018181       \t|\n",
            "training_step_end                  \t|  3.2972e-05     \t|69             \t|  0.0022751      \t|  0.015847       \t|\n",
            "validation_step_end                \t|  7.6789e-05     \t|23             \t|  0.0017661      \t|  0.012302       \t|\n",
            "on_validation_epoch_end            \t|  5.1017e-05     \t|23             \t|  0.0011734      \t|  0.008173       \t|\n",
            "on_validation_epoch_start          \t|  2.9762e-05     \t|23             \t|  0.00068453     \t|  0.0047679      \t|\n",
            "on_test_end                        \t|  0.00040395     \t|1              \t|  0.00040395     \t|  0.0028136      \t|\n",
            "on_test_start                      \t|  0.0003718      \t|1              \t|  0.0003718      \t|  0.0025897      \t|\n",
            "on_train_start                     \t|  0.0003531      \t|1              \t|  0.0003531      \t|  0.0024595      \t|\n",
            "on_train_end                       \t|  0.00030467     \t|1              \t|  0.00030467     \t|  0.0021221      \t|\n",
            "on_test_batch_start                \t|  0.00017779     \t|1              \t|  0.00017779     \t|  0.0012384      \t|\n",
            "on_test_batch_end                  \t|  0.00015963     \t|1              \t|  0.00015963     \t|  0.0011118      \t|\n",
            "on_before_accelerator_backend_setup\t|  4.8926e-05     \t|2              \t|  9.7852e-05     \t|  0.00068157     \t|\n",
            "test_step_end                      \t|  8.6238e-05     \t|1              \t|  8.6238e-05     \t|  0.00060067     \t|\n",
            "on_fit_end                         \t|  6.5144e-05     \t|1              \t|  6.5144e-05     \t|  0.00045375     \t|\n",
            "on_test_epoch_end                  \t|  4.9108e-05     \t|1              \t|  4.9108e-05     \t|  0.00034205     \t|\n",
            "on_fit_start                       \t|  4.1322e-05     \t|1              \t|  4.1322e-05     \t|  0.00028782     \t|\n",
            "on_test_epoch_start                \t|  2.6884e-05     \t|1              \t|  2.6884e-05     \t|  0.00018725     \t|\n",
            "on_test_dataloader                 \t|  1.9894e-05     \t|1              \t|  1.9894e-05     \t|  0.00013857     \t|\n",
            "on_train_dataloader                \t|  1.9524e-05     \t|1              \t|  1.9524e-05     \t|  0.00013599     \t|\n",
            "on_val_dataloader                  \t|  1.7666e-05     \t|1              \t|  1.7666e-05     \t|  0.00012305     \t|\n",
            "\n",
            "TEST RESULTS {\"test_score\": 0.0833333358168602, \"test_loss\": 19.56671142578125, \"test_top1_acc\": 0.0833333358168602, \"validation_score\": 0.04545454680919647, \"hparams\": {\"batch_size\": 1024, \"check_val_every_n_epoch\": 3, \"dropout\": 0.1, \"embedding_norm\": \"<class 'torch.nn.modules.linear.Identity'>\", \"hidden_dim\": 1024, \"hidden_layers\": 1, \"hidden_norm\": \"<class 'torch.nn.modules.batchnorm.BatchNorm1d'>\", \"initialization\": \"<function xavier_normal_ at 0x7fe10adf88c0>\", \"lr\": 0.0001, \"max_epochs\": 500, \"norm_after_activation\": false, \"optim\": \"<class 'torch.optim.adam.Adam'>\", \"patience\": 20}, \"postprocessing\": [], \"epoch\": 9, \"time_in_min\": 0.2378027598063151, \"score_mode\": \"max\", \"embedding_path\": \"embeddings/hearbaseline/speech_commands-v0.0.2-small\"}\n",
            "DONE. took 14.499086856842041 seconds to complete task_predictions(embedding_path=embeddings/hearbaseline/speech_commands-v0.0.2-small, embedding_size=4096, grid_points=1, gpus=None, in_memory=True, deterministic=True, grid=default)\n",
            "100% 1/1 [00:14<00:00, 14.50s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImPvomao3E-5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}